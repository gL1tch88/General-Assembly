{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Countries = {\"AU\":\"Australia\"}\n",
    "\n",
    "Target_cities= {'AU':[\"Sydney\",\"Melbourne\",\"Brisbane\",\"Perth\", \"Adelaide\", \"Canberra\", \"Darwin\", \"Hobart\"]}\n",
    "\n",
    "URL ={\"AU\":\"https://au.indeed.com/jobs\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## maximum search results\n",
    "max_results_per_city = 1000\n",
    "## Search parameters on url\n",
    "## placeholders\n",
    "parameters = {'q': 'data scientist', 'radius': '100', 'start':1}\n",
    "jobs = ['data scientist','data analyst', 'data engineer', 'big data', 'cloud', 'business intelligence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page_to_df(url, url_params, country):\n",
    "\n",
    "    # create a empty dictionary to store extracted information for each page\n",
    "    scraped_data = {'location': [],\n",
    "                  'company': [],\n",
    "                  'title': [],\n",
    "                  'salary': [],\n",
    "                  'description': [],\n",
    "                  'review': [],\n",
    "                  'star': [],\n",
    "                  'country': []\n",
    "                  }\n",
    "\n",
    "    html = requests.get(url, params=url_params)\n",
    "\n",
    "    # make sure the response status is ok\n",
    "    assert html.status_code == requests.codes.ok\n",
    "    \n",
    "    soup = BeautifulSoup(html.text, 'lxml')\n",
    "\n",
    "    # function to extract results for each search page\n",
    "\n",
    "    def extract_results(soup):\n",
    "        return soup.find_all('div', class_='result')\n",
    "\n",
    "    results = extract_results(soup)\n",
    "\n",
    "    ## input html for each search object and extract jobs information\n",
    "\n",
    "    def extract_location(result):\n",
    "        \"\"\"extract job location\"\"\"\n",
    "        try:\n",
    "            location = result.find('span', class_='location').get_text().strip()\n",
    "            return location\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def extract_company(result):\n",
    "        \"\"\"extract the name of the company\"\"\"\n",
    "        try:\n",
    "            company = result.find('span', class_='company').get_text().strip()\n",
    "            return company\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def extract_title(result):\n",
    "        \"\"\"extract the job title\"\"\"\n",
    "        try:\n",
    "            title = result.find('a', attrs={'data-tn-element': \"jobTitle\"}).get('title')\n",
    "            return title\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def extract_salary(result):\n",
    "        \"\"\"extract the salary\"\"\"\n",
    "        try:\n",
    "            salary = result.find('div', class_='salarySnippet salarySnippetDemphasizeholisticSalary').\\\n",
    "            find('span', class_='no-wrap').\\\n",
    "            get_text().strip()\n",
    "            \n",
    "            return salary\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def extract_description(result):\n",
    "        \"\"\"extract job description snippet\"\"\"\n",
    "        try:\n",
    "            description = result.find('div', class_= 'summary').get_text().strip()\n",
    "            return description\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def extract_review(result):\n",
    "        \"\"\"extract the number of reviews for the company\"\"\"\n",
    "        try:\n",
    "            review = result.find('a', attrs={'data-tn-element': \"reviewStars\"})\n",
    "            review = review.find('span', class_=\"slNoUnderline\")\n",
    "            review = review.get_text().strip()\n",
    "            # extract only the number\n",
    "            review = review.replace(',', '').replace(' reviews', '')\n",
    "            return review\n",
    "        except:\n",
    "            return None            \n",
    "\n",
    "    \n",
    "    def extract_star(result):\n",
    "        \"\"\"extract a number (width) that is proportional to the number of stars\n",
    "        shown for the company\"\"\"\n",
    "        try:\n",
    "            # the 'style' attribute dictates how many stars are filled with color\n",
    "            star = result.find('span', class_='rating').get('style')\n",
    "            # extract only the number\n",
    "            star = star.replace('width:', '').replace('px', '')\n",
    "            return star\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    # append extracted info to the correspond list\n",
    "    for result in results:\n",
    "        scraped_data['location'].append(extract_location(result))\n",
    "        scraped_data['company'].append(extract_company(result))\n",
    "        scraped_data['title'].append(extract_title(result))\n",
    "        scraped_data['salary'].append(extract_salary(result))\n",
    "        scraped_data['description'].append(extract_description(result))\n",
    "        scraped_data['review'].append(extract_review(result))\n",
    "        scraped_data['star'].append(extract_star(result))\n",
    "        scraped_data['country'].append(country)\n",
    "\n",
    "    # convert the dictionary to a pandas dataframe and returns it\n",
    "    return pd.DataFrame(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"remove duplicates and returns a new df\"\"\"\n",
    "    \n",
    "    nrows_before = df.shape[0]\n",
    "    df.drop_duplicates(subset=['company', 'country','description',\n",
    "                               'location', 'salary', 'title'],\n",
    "                       keep='last', inplace=True)\n",
    "    nrows_after = df.shape[0]\n",
    "    \n",
    "    print('{} rows remain after removing duplicates from {} rows.'.format(\n",
    "        nrows_after, nrows_before))\n",
    "    print('{} rows have salary info; {} rows have yearly salary info.'.format(\n",
    "      df.salary.notnull().sum(), df.salary.str.contains('year').sum()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapper(CountryCode):\n",
    "    print('Current system time: {}'.format(time.ctime()))\n",
    " \n",
    "    # scrape data and save to dataframe\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Retrieve Parameters to scrape with based on input of Country Code\n",
    "    url = URL[CountryCode]\n",
    "    locations = Target_cities[CountryCode]\n",
    "    country = Countries[CountryCode]\n",
    "    \n",
    "    #Create an empty place holder df, search through every location in that country, but only 1 results, just to get the title and columns\n",
    "    df = scrape_page_to_df(url,parameters,country)\n",
    "    \n",
    "    for loc in locations:\n",
    "        for work in jobs:\n",
    "            for start in range(0, max_results_per_city, 10):\n",
    "            \n",
    "              \n",
    "                url_params = parameters.copy()\n",
    "                #update the job with the target job that we want, city for target city that we are looking for and start refers to the current page number being scrapped\n",
    "                url_params.update({'l': loc,'q': work, 'start': start})\n",
    "\n",
    "\n",
    "                #insert code to put the scrap stuff into a df here, after each round of loop, concat into a df\n",
    "                df = pd.concat([df,scrape_page_to_df(url, url_params,country)],axis=0)\n",
    "              \n",
    "        print('Finished scraping {}'.format(loc))\n",
    "    total_time = (time.time() - start_time) / 60\n",
    "    print('Scraping run time: {:.1f} minutes'.format(total_time))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # remove duplicates\n",
    "    df = remove_duplicates(df)\n",
    "    print('Script finished at {}\\n'.format(time.ctime()))\n",
    "    \n",
    "    #returns the final df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current system time: Fri Feb 21 21:50:23 2020\n",
      "Finished scraping Sydney\n",
      "Finished scraping Melbourne\n",
      "Finished scraping Brisbane\n",
      "Finished scraping Perth\n",
      "Finished scraping Adelaide\n",
      "Finished scraping Canberra\n",
      "Finished scraping Darwin\n",
      "Finished scraping Hobart\n",
      "Scraping run time: 54.5 minutes\n",
      "10688 rows remain after removing duplicates from 56601 rows.\n",
      "2034 rows have salary info; 1545 rows have yearly salary info.\n",
      "Script finished at Fri Feb 21 22:44:51 2020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AU = scrapper('AU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>review</th>\n",
       "      <th>star</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>International Institute of Data &amp; Analytics</td>\n",
       "      <td>Junior Data Analyst/Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>In data science and big data analytics, the ID...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>AWS Australia Pty Ltd</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Strong communication and data presentation ski...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Atlassian</td>\n",
       "      <td>Senior Data Scientist, DevOps Product Analytics</td>\n",
       "      <td>None</td>\n",
       "      <td>Play with our seriously large volume of analyt...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>North Sydney NSW</td>\n",
       "      <td>Harwood Environmental Consultants</td>\n",
       "      <td>Graduate Environmental Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>To develop the skills required to achieve fiel...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Freelancer.com</td>\n",
       "      <td>Data Analyst / Junior Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>We are a data-driven company - data trumps opi...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cambridge TAS</td>\n",
       "      <td>Trouw Nutrition Canada Inc.</td>\n",
       "      <td>Technical Officer</td>\n",
       "      <td>None</td>\n",
       "      <td>Take appropriate action as agreed with the Key...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hobart TAS</td>\n",
       "      <td>Weir Minerals</td>\n",
       "      <td>Area Manager</td>\n",
       "      <td>None</td>\n",
       "      <td>To support the Weir Minerals business by provi...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Otago TAS</td>\n",
       "      <td>APM</td>\n",
       "      <td>APM - Team Co-ordinator - Dunedin</td>\n",
       "      <td>None</td>\n",
       "      <td>Working with our regional manager to explore n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Otago TAS</td>\n",
       "      <td>APM</td>\n",
       "      <td>APM - Team Co-ordinator - Central Otago</td>\n",
       "      <td>None</td>\n",
       "      <td>Working with our regional manager to explore n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hobart TAS</td>\n",
       "      <td>Searson Buck</td>\n",
       "      <td>Recruitment Consultant - Professional Services</td>\n",
       "      <td>None</td>\n",
       "      <td>Use influencing skills, and demonstrate empath...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10688 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            location                                      company  \\\n",
       "3         Sydney NSW  International Institute of Data & Analytics   \n",
       "5         Sydney NSW                        AWS Australia Pty Ltd   \n",
       "7         Sydney NSW                                    Atlassian   \n",
       "10  North Sydney NSW            Harwood Environmental Consultants   \n",
       "11        Sydney NSW                               Freelancer.com   \n",
       "..               ...                                          ...   \n",
       "4      Cambridge TAS                  Trouw Nutrition Canada Inc.   \n",
       "5         Hobart TAS                                Weir Minerals   \n",
       "6          Otago TAS                                          APM   \n",
       "7          Otago TAS                                          APM   \n",
       "8         Hobart TAS                                 Searson Buck   \n",
       "\n",
       "                                              title salary  \\\n",
       "3                     Junior Data Analyst/Scientist   None   \n",
       "5                                Sr. Data Scientist   None   \n",
       "7   Senior Data Scientist, DevOps Product Analytics   None   \n",
       "10                 Graduate Environmental Scientist   None   \n",
       "11             Data Analyst / Junior Data Scientist   None   \n",
       "..                                              ...    ...   \n",
       "4                                 Technical Officer   None   \n",
       "5                                      Area Manager   None   \n",
       "6                 APM - Team Co-ordinator - Dunedin   None   \n",
       "7           APM - Team Co-ordinator - Central Otago   None   \n",
       "8    Recruitment Consultant - Professional Services   None   \n",
       "\n",
       "                                          description review  star    country  \n",
       "3   In data science and big data analytics, the ID...   None  None  Australia  \n",
       "5   Strong communication and data presentation ski...   None  None  Australia  \n",
       "7   Play with our seriously large volume of analyt...   None  None  Australia  \n",
       "10  To develop the skills required to achieve fiel...   None  None  Australia  \n",
       "11  We are a data-driven company - data trumps opi...   None  None  Australia  \n",
       "..                                                ...    ...   ...        ...  \n",
       "4   Take appropriate action as agreed with the Key...   None  None  Australia  \n",
       "5   To support the Weir Minerals business by provi...   None  None  Australia  \n",
       "6   Working with our regional manager to explore n...   None  None  Australia  \n",
       "7   Working with our regional manager to explore n...   None  None  Australia  \n",
       "8   Use influencing skills, and demonstrate empath...   None  None  Australia  \n",
       "\n",
       "[10688 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = pd.DataFrame(AU)\n",
    "df_job.to_csv('Job_final_output_v6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_job = pd.read_csv('./Job_final_output_v6.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>review</th>\n",
       "      <th>star</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>International Institute of Data &amp; Analytics</td>\n",
       "      <td>Junior Data Analyst/Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In data science and big data analytics, the ID...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>AWS Australia Pty Ltd</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strong communication and data presentation ski...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Atlassian</td>\n",
       "      <td>Senior Data Scientist, DevOps Product Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Play with our seriously large volume of analyt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>North Sydney NSW</td>\n",
       "      <td>Harwood Environmental Consultants</td>\n",
       "      <td>Graduate Environmental Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To develop the skills required to achieve fiel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Freelancer.com</td>\n",
       "      <td>Data Analyst / Junior Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are a data-driven company - data trumps opi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cambridge TAS</td>\n",
       "      <td>Trouw Nutrition Canada Inc.</td>\n",
       "      <td>Technical Officer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Take appropriate action as agreed with the Key...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hobart TAS</td>\n",
       "      <td>Weir Minerals</td>\n",
       "      <td>Area Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To support the Weir Minerals business by provi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Otago TAS</td>\n",
       "      <td>APM</td>\n",
       "      <td>APM - Team Co-ordinator - Dunedin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working with our regional manager to explore n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Otago TAS</td>\n",
       "      <td>APM</td>\n",
       "      <td>APM - Team Co-ordinator - Central Otago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working with our regional manager to explore n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hobart TAS</td>\n",
       "      <td>Searson Buck</td>\n",
       "      <td>Recruitment Consultant - Professional Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Use influencing skills, and demonstrate empath...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10688 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            location                                      company  \\\n",
       "3         Sydney NSW  International Institute of Data & Analytics   \n",
       "5         Sydney NSW                        AWS Australia Pty Ltd   \n",
       "7         Sydney NSW                                    Atlassian   \n",
       "10  North Sydney NSW            Harwood Environmental Consultants   \n",
       "11        Sydney NSW                               Freelancer.com   \n",
       "..               ...                                          ...   \n",
       "4      Cambridge TAS                  Trouw Nutrition Canada Inc.   \n",
       "5         Hobart TAS                                Weir Minerals   \n",
       "6          Otago TAS                                          APM   \n",
       "7          Otago TAS                                          APM   \n",
       "8         Hobart TAS                                 Searson Buck   \n",
       "\n",
       "                                              title salary  \\\n",
       "3                     Junior Data Analyst/Scientist    NaN   \n",
       "5                                Sr. Data Scientist    NaN   \n",
       "7   Senior Data Scientist, DevOps Product Analytics    NaN   \n",
       "10                 Graduate Environmental Scientist    NaN   \n",
       "11             Data Analyst / Junior Data Scientist    NaN   \n",
       "..                                              ...    ...   \n",
       "4                                 Technical Officer    NaN   \n",
       "5                                      Area Manager    NaN   \n",
       "6                 APM - Team Co-ordinator - Dunedin    NaN   \n",
       "7           APM - Team Co-ordinator - Central Otago    NaN   \n",
       "8    Recruitment Consultant - Professional Services    NaN   \n",
       "\n",
       "                                          description  review  star    country  \n",
       "3   In data science and big data analytics, the ID...     NaN   NaN  Australia  \n",
       "5   Strong communication and data presentation ski...     NaN   NaN  Australia  \n",
       "7   Play with our seriously large volume of analyt...     NaN   NaN  Australia  \n",
       "10  To develop the skills required to achieve fiel...     NaN   NaN  Australia  \n",
       "11  We are a data-driven company - data trumps opi...     NaN   NaN  Australia  \n",
       "..                                                ...     ...   ...        ...  \n",
       "4   Take appropriate action as agreed with the Key...     NaN   NaN  Australia  \n",
       "5   To support the Weir Minerals business by provi...     NaN   NaN  Australia  \n",
       "6   Working with our regional manager to explore n...     NaN   NaN  Australia  \n",
       "7   Working with our regional manager to explore n...     NaN   NaN  Australia  \n",
       "8   Use influencing skills, and demonstrate empath...     NaN   NaN  Australia  \n",
       "\n",
       "[10688 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape = store_job[['title', 'company', 'location', 'salary', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape.columns = ['job_title', 'company_name', 'location', 'salary', 'job_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>job_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Analyst/Scientist</td>\n",
       "      <td>International Institute of Data &amp; Analytics</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In data science and big data analytics, the ID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>AWS Australia Pty Ltd</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strong communication and data presentation ski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist, DevOps Product Analytics</td>\n",
       "      <td>Atlassian</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Play with our seriously large volume of analyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Graduate Environmental Scientist</td>\n",
       "      <td>Harwood Environmental Consultants</td>\n",
       "      <td>North Sydney NSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To develop the skills required to achieve fiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst / Junior Data Scientist</td>\n",
       "      <td>Freelancer.com</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are a data-driven company - data trumps opi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technical Officer</td>\n",
       "      <td>Trouw Nutrition Canada Inc.</td>\n",
       "      <td>Cambridge TAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Take appropriate action as agreed with the Key...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Area Manager</td>\n",
       "      <td>Weir Minerals</td>\n",
       "      <td>Hobart TAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To support the Weir Minerals business by provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>APM - Team Co-ordinator - Dunedin</td>\n",
       "      <td>APM</td>\n",
       "      <td>Otago TAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working with our regional manager to explore n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>APM - Team Co-ordinator - Central Otago</td>\n",
       "      <td>APM</td>\n",
       "      <td>Otago TAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Working with our regional manager to explore n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recruitment Consultant - Professional Services</td>\n",
       "      <td>Searson Buck</td>\n",
       "      <td>Hobart TAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Use influencing skills, and demonstrate empath...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10688 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_title  \\\n",
       "3                     Junior Data Analyst/Scientist   \n",
       "5                                Sr. Data Scientist   \n",
       "7   Senior Data Scientist, DevOps Product Analytics   \n",
       "10                 Graduate Environmental Scientist   \n",
       "11             Data Analyst / Junior Data Scientist   \n",
       "..                                              ...   \n",
       "4                                 Technical Officer   \n",
       "5                                      Area Manager   \n",
       "6                 APM - Team Co-ordinator - Dunedin   \n",
       "7           APM - Team Co-ordinator - Central Otago   \n",
       "8    Recruitment Consultant - Professional Services   \n",
       "\n",
       "                                   company_name          location salary  \\\n",
       "3   International Institute of Data & Analytics        Sydney NSW    NaN   \n",
       "5                         AWS Australia Pty Ltd        Sydney NSW    NaN   \n",
       "7                                     Atlassian        Sydney NSW    NaN   \n",
       "10            Harwood Environmental Consultants  North Sydney NSW    NaN   \n",
       "11                               Freelancer.com        Sydney NSW    NaN   \n",
       "..                                          ...               ...    ...   \n",
       "4                   Trouw Nutrition Canada Inc.     Cambridge TAS    NaN   \n",
       "5                                 Weir Minerals        Hobart TAS    NaN   \n",
       "6                                           APM         Otago TAS    NaN   \n",
       "7                                           APM         Otago TAS    NaN   \n",
       "8                                  Searson Buck        Hobart TAS    NaN   \n",
       "\n",
       "                                             job_desc  \n",
       "3   In data science and big data analytics, the ID...  \n",
       "5   Strong communication and data presentation ski...  \n",
       "7   Play with our seriously large volume of analyt...  \n",
       "10  To develop the skills required to achieve fiel...  \n",
       "11  We are a data-driven company - data trumps opi...  \n",
       "..                                                ...  \n",
       "4   Take appropriate action as agreed with the Key...  \n",
       "5   To support the Weir Minerals business by provi...  \n",
       "6   Working with our regional manager to explore n...  \n",
       "7   Working with our regional manager to explore n...  \n",
       "8   Use influencing skills, and demonstrate empath...  \n",
       "\n",
       "[10688 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape.to_csv('Job_final_output_v7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
